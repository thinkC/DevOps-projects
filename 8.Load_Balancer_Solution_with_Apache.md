
## Configure Apache As A Load Balancer

We continue our project from the last project [_LAMP Stack Tooling website Application_](https://github.com/thinkC/devops-projects/blob/master/7.DevOps_Tooling_Website_Solution.md) .

In this project...

1. We create an EC2 server running Ubuntu 20.04 and name it _Project-8-apache-lb_. We also create security group for this server and open port 22 for SSH.
 Our setup should now look like below

![servers](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img23-p8.PNG?raw=true)

2. Allow HTTP port 80 on _Project-8-apache-lb_ server

![servers](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img24-p8.PNG?raw=true).

3. Next, we install Apache load balancer on server _Project-8-apache-lb_ and configure it to point to traffic coming to (LB) Load Balancer to both web servers.

```bash
#Install apache2
sudo apt update
sudo apt install apache2 -y
sudo apt-get install libxml2-dev

#Enable following modules:
sudo a2enmod rewrite
sudo a2enmod proxy
sudo a2enmod proxy_balancer
sudo a2enmod proxy_http
sudo a2enmod headers
sudo a2enmod lbmethod_bytraffic

#Restart apache2 service
sudo systemctl restart apache2
```

We make sure Apache is up and running

```bash
sudo systemctl status apache2
```

output

```bash
● apache2.service - The Apache HTTP Server
     Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2021-07-09 19:48:16 UTC; 20s ago
       Docs: https://httpd.apache.org/docs/2.4/
    Process: 17714 ExecStart=/usr/sbin/apachectl start (code=exited, status=0/SUCCESS)
   Main PID: 17728 (apache2)
      Tasks: 55 (limit: 1160)
     Memory: 5.5M
     CGroup: /system.slice/apache2.service
             ├─17728 /usr/sbin/apache2 -k start
             ├─17729 /usr/sbin/apache2 -k start
             └─17730 /usr/sbin/apache2 -k start

Jul 09 19:48:16 ip-172-31-0-45 systemd[1]: Starting The Apache HTTP Server...
Jul 09 19:48:16 ip-172-31-0-45 systemd[1]: Started The Apache HTTP Server.
```

## Configure load balancing

We update _/etc/apache2/sites-available/000-default.conf_ . Add Private IP address for web server1 and web server 2

```bash
sudo nano /etc/apache2/sites-available/000-default.conf

#Add this configuration into this section <VirtualHost *:80>  </VirtualHost>

<Proxy "balancer://mycluster">
               BalancerMember http://<WebServer1-Private-IP-Address>:80 loadfactor=5 timeout=1
               BalancerMember http://<WebServer2-Private-IP-Address>:80 loadfactor=5 timeout=1
               ProxySet lbmethod=bytraffic
               # ProxySet lbmethod=byrequests
        </Proxy>

        ProxyPreserveHost On
        ProxyPass / balancer://mycluster/
        ProxyPassReverse / balancer://mycluster/

#Restart apache server

sudo systemctl restart apache2
```

Check Apache2 status

```bash
sudo systemctl status apache2
```

output

```bash
● apache2.service - The Apache HTTP Server
     Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2021-07-09 20:36:34 UTC; 21s ago
       Docs: https://httpd.apache.org/docs/2.4/
    Process: 17897 ExecStart=/usr/sbin/apachectl start (code=exited, status=0/SUCCESS)
   Main PID: 17912 (apache2)
      Tasks: 55 (limit: 1160)
     Memory: 5.5M
     CGroup: /system.slice/apache2.service
             ├─17912 /usr/sbin/apache2 -k start
             ├─17913 /usr/sbin/apache2 -k start
             └─17914 /usr/sbin/apache2 -k start

Jul 09 20:36:34 ip-172-31-0-45 systemd[1]: Stopping The Apache HTTP Server...
Jul 09 20:36:34 ip-172-31-0-45 systemd[1]: apache2.service: Succeeded.
Jul 09 20:36:34 ip-172-31-0-45 systemd[1]: Stopped The Apache HTTP Server.
Jul 09 20:36:34 ip-172-31-0-45 systemd[1]: Starting The Apache HTTP Server...
Jul 09 20:36:34 ip-172-31-0-45 systemd[1]: Started The Apache HTTP Server.
```



![site-available](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img25-p8.PNG?raw=true)

Note: Since in project _LAMP Stack Tooling website Application_ we mounted _/var/log/httpd/_ on our web servers to the NFS logical volume, we will umount its so that we can view differently the web server logs.

Run code below on web server1 and web server2 to unmount.

```bash
 sudo umount -l /dev/nfs-vg/lv-logs /var/log/httpd
```

Note when I ran code below to unmount I was getting device busy so I could not umount so I used the umount with the -l switch

```bash
sudo umount /dev/nfs-vg/lv-logs /var/log/httpd
```

4. Next, we check if our configuration works on the Apache Load Balancer and see if we are still able to access the Web Tooling Application. Here we are able to access the Web Tooling App with the Apache Load Balancer Public and Public DNS Address.

![Load balancer](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img26-p8.PNG?raw=true)

![Load balancer](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img27-p8.PNG?raw=true)

Next, we try to see the number of HTTP request received by both web servers when we access the tooling websiet and try refreshing the page several times.

We run command below on both web servers. You will notice that both servers have equal number of request since the _loadfactor_ we configured... is the same for both servers. This means traffic are distributed evenly and users will not even notice they are been served from different servers.

```bash
sudo tail -f /var/log/httpd/access_log
```
log for webserver1
![logs](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img28-webserver1-log-p8.PNG?raw=true)

log for webserver2
![logs](https://github.com/thinkC/devops-projects/blob/master/img-web-tooling/img29-webserver2-log-p8.PNG?raw=true)

Congratulations, we are able to access both web servers from our Apache's Load Balancer.